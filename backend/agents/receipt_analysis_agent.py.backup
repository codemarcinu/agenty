import asyncio
import contextlib
import logging
import re
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import numpy as np
from PIL import Image, ImageEnhance, ImageFilter

from backend.agents.base_agent import BaseAgent
from backend.agents.interfaces import AgentResponse
from backend.core.anti_hallucination_decorator import (
    AntiHallucinationConfig,
    with_anti_hallucination,
)
from backend.core.anti_hallucination_system import ValidationLevel
from backend.core.feedback_loop import log_failed_extraction
from backend.core.hybrid_llm_client import hybrid_llm_client, HybridLLMClient
from backend.core.normalizer_adapter import NormalizerAdapter
from backend.core.product_categorizer import ProductCategorizer
from backend.core.receipt_validation import receipt_validator
from backend.core.store_normalization import normalize_store_name
from backend.core.timeout_manager import TimeoutConfig, timeout_manager

logger = logging.getLogger(__name__)


class ReceiptAnalysisAgent(BaseAgent):
    """Agent odpowiedzialny za analizę danych paragonu po przetworzeniu OCR.

    Ten agent analizuje tekst OCR i wyciąga strukturalne informacje:
    - Nazwa sklepu (znormalizowana)
    - Data zakupów
    - Produkty z znormalizowanymi nazwami
    - Ilości i jednostki miary
    - Ceny jednostkowe
    - Rabaty/promocje
    - Cena całkowita
    - Kategorie produktowe z Google Product Taxonomy

    Zoptymalizowany z pre-processing obrazów i batch processing.
    """

    def __init__(
        self,
        name: str = "ReceiptAnalysisAgent",
        error_handler=None,
        fallback_manager=None,
        **kwargs,
    ) -> None:
        super().__init__(
            name=name,
            error_handler=error_handler,
            fallback_manager=fallback_manager,
            **kwargs,
        )

        # Mapowanie kategorii produktów dla polskich sklepów - ulepszone
        self.category_mapping = {
            # Przyprawy i sosy
            "Pesto": "Przyprawy i sosy",
            "Sos": "Przyprawy i sosy",
            "Ketchup": "Przyprawy i sosy",
            "Majonez": "Przyprawy i sosy",
            # Napoje
            "Kawa": "Napoje > Kawa i herbata",
            "Herbata": "Napoje > Kawa i herbata",
            "KawZiar": "Napoje > Kawa i herbata",
            "Dorbar": "Napoje > Kawa i herbata",
            # Mrożonki
            "Frytki": "Mrożonki",
            "Frytkikarbmrpot": "Mrożonki",
            "Lody": "Mrożonki",
            "Pizza": "Mrożonki",
            # Nabiał
            "Jogurt": "Nabiał > Jogurty",
            "Skyr": "Nabiał > Jogurty",
            "Masło": "Nabiał > Masło i margaryna",
            "Mleko": "Nabiał > Mleko i śmietana",
            "Ser": "Nabiał > Sery",
            "Śmietana": "Nabiał > Mleko i śmietana",
            "Twaróg": "Nabiał > Twarogi",
            # Pieczywo
            "Chleb": "Pieczywo > Chleby",
            "Bułka": "Pieczywo > Bułki",
            "Rogal": "Pieczywo > Rogale i croissanty",
            "Bagietka": "Pieczywo > Bagietki",
            # Mięso i wędliny
            "Kiełbasa": "Mięso i wędliny > Kiełbasy",
            "Szynka": "Mięso i wędliny > Szynki",
            "Boczek": "Mięso i wędliny > Boczek",
            "Kurczak": "Mięso i wędliny > Drób",
            "Wieprzowina": "Mięso i wędliny > Wieprzowina",
            "Wołowina": "Mięso i wędliny > Wołowina",
            # Owoce i warzywa
            "Banan": "Owoce i warzywa > Owoce",
            "Jabłko": "Owoce i warzywa > Owoce",
            "Pomidor": "Owoce i warzywa > Warzywa",
            "Ogórek": "Owoce i warzywa > Warzywa",
            "Marchew": "Owoce i warzywa > Warzywa",
            "Cebula": "Owoce i warzywa > Warzywa",
            "Ziemniak": "Owoce i warzywa > Warzywa",
            # Napoje
            "Woda": "Napoje > Wody",
            "Sok": "Napoje > Soki",
            "Cola": "Napoje > Napoje gazowane",
            "Piwo": "Napoje > Piwa",
            "Wino": "Napoje > Wina",
            # Słodycze
            "Czekolada": "Słodycze > Czekolady",
            "Cukierki": "Słodycze > Cukierki",
            "Lizak": "Słodycze > Lizaki",
            "Guma": "Słodycze > Gumy do żucia",
            # Przekąski
            "Chipsy": "Przekąski > Chipsy",
            "Orzeszki": "Przekąski > Orzeszki",
            "Paluszki": "Przekąski > Paluszki",
            "Krakersy": "Przekąski > Krakersy",
            # Konserwy
            "Tuńczyk": "Konserwy > Ryby",
            "Sardynki": "Konserwy > Ryby",
            "Groszek": "Konserwy > Warzywa",
            "Fasola": "Konserwy > Warzywa",
            # Mrożonki
            "Lody": "Mrożonki > Lody",
            "Pizza": "Mrożonki > Pizze",
            "Frytki": "Mrożonki > Frytki i przekąski",
            # Przyprawy i sosy
            "Ketchup": "Przyprawy i sosy > Ketchupy",
            "Majonez": "Przyprawy i sosy > Majonezy",
            "Musztarda": "Przyprawy i sosy > Musztardy",
            "Ocet": "Przyprawy i sosy > Octy",
            "Olej": "Przyprawy i sosy > Oleje",
            # Chemia gospodarcza
            "Proszek": "Chemia gospodarcza > Proszki do prania",
            "Płyn": "Chemia gospodarcza > Płyny",
            "Papier": "Chemia gospodarcza > Papier toaletowy",
            "Szampon": "Chemia gospodarcza > Szampony",
            "Pasta": "Chemia gospodarcza > Pasty do zębów",
        }

        # Performance metrics
        self.performance_metrics = {
            "total_receipts": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_processing_time": 0.0,
            "total_processing_time": 0.0,
            "batch_processed": 0,
            "preprocessing_used": 0,
        }

        # Performance optimization settings
        self.batch_processing_enabled = kwargs.get("batch_processing_enabled", True)
        self.max_batch_size = kwargs.get("max_batch_size", 5)
        self.preprocessing_enabled = kwargs.get("preprocessing_enabled", True)

        # Inicjalizuj kategoryzator produktów i adapter normalizacji
        self.product_categorizer = ProductCategorizer()
        self.normalizer_adapter = NormalizerAdapter()

    async def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        Pre-processing obrazu przed OCR dla lepszej jakości rozpoznawania.
        """
        try:
            # Wczytaj obraz
            image = Image.open(image_path)

            # Konwertuj do RGB jeśli potrzebne
            if image.mode != "RGB":
                image = image.convert("RGB")

            # Zwiększ kontrast
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.5)

            # Zwiększ ostrość
            image = image.filter(ImageFilter.SHARPEN)

            # Zmniejsz rozmiar jeśli za duży (przyspiesza OCR)
            max_size = (1920, 1080)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)

            # Konwertuj do numpy array
            return np.array(image)

        except Exception as e:
            logger.warning(f"Image preprocessing failed: {e}")
            # Fallback - wczytaj oryginalny obraz
            return np.array(Image.open(image_path))

    async def process_receipts_batch(
        self, receipt_data_list: list[dict[str, Any]]
    ) -> list[AgentResponse]:
        """
        Przetwarza listę paragonów w batch mode z optymalizacją wydajności.
        """
        results = []
        
        for receipt_data in receipt_data_list:
            try:
                result = await self.process(receipt_data)
                results.append(result)
            except Exception as e:
                logger.error(f"Błąd w batch processing: {e}")
                # Dodaj błąd do wyników zamiast przerywać cały batch
                error_result = AgentResponse(
                    success=False,
                    error=str(e),
                    text=f"Błąd podczas przetwarzania paragonu: {e}",
                )
                results.append(error_result)
            else:
                results.append(result)

            self.performance_metrics["batch_processed"] += 1

        return results

    def _parse_llm_response(self, content: str) -> dict[str, Any] | None:
        """Parsuje odpowiedź LLM i wyciąga strukturalne dane JSON"""
        try:
            # Wyodrębnij JSON z odpowiedzi LLM
            from backend.core.utils import extract_json_from_text
            json_str = extract_json_from_text(content)
            
            if json_str:
                import json
                parsed_data = json.loads(json_str)
                
                # Sprawdź czy to słownik
                if isinstance(parsed_data, dict):
                    logger.info("Pomyślnie sparsowano odpowiedź LLM")
                    return parsed_data
                else:
                    logger.warning(f"LLM zwrócił nieprawidłowy format: {type(parsed_data)}")
                    return None
                    
            logger.warning("Nie znaleziono JSON w odpowiedzi LLM")
            return None
            
        except json.JSONDecodeError as e:
            logger.error(f"Błąd parsowania JSON z odpowiedzi LLM: {e}")
            return None
        except Exception as e:
            logger.error(f"Błąd parsowania odpowiedzi LLM: {e}")
            return None

    @with_anti_hallucination(
        AntiHallucinationConfig(
            validation_level=ValidationLevel.STRICT, log_validation=True
        )
    )
    async def process(self, input_data: dict[str, Any]) -> AgentResponse:
        """
        Analizuje paragon i wyciąga strukturalne dane
        Zoptymalizowane z pre-processing i pomiarem wydajności.
        """
        start_time = time.time()

        try:
            # Extract OCR text from input
            ocr_text = input_data.get("ocr_text", "")
            image_path = input_data.get("image_path", "")

            if not ocr_text:
                            return AgentResponse(
                success=False,
                error="Brak tekstu OCR do analizy",
                text="Brak tekstu OCR do analizy",
            )

            # Step 1: Preprocessing tekstu OCR z korekcją błędów
            from backend.core.ocr import OCRProcessor

            ocr_processor = OCRProcessor()
            preprocessed_text = ocr_processor.preprocess_ocr_text(ocr_text)

            if preprocessed_text != ocr_text:
                logger.info("Zastosowano preprocessing tekstu OCR")
                # Użyj przeprocesowanego tekstu dla analizy
                ocr_text = preprocessed_text

            # Step 2: Filtrowanie produktów od metadanych
            lines = ocr_text.split("\n")
            filtered_products = ocr_processor.filter_products(lines)

            if len(filtered_products) < len(lines):
                logger.info(
                    f"Przefiltrowano {len(lines)} linii do {len(filtered_products)} produktów"
                )
                # Zachowaj oryginalny tekst dla analizy, ale użyj przefiltrowanych produktów dla LLM
                # ocr_text pozostaje niezmieniony dla fallback parsera

            # Pre-processing obrazu jeśli dostępny
            if image_path and self.preprocessing_enabled:
                try:
                    await self.preprocess_image(image_path)
                    # Tutaj można przekazać preprocessed_image do OCR
                    self.performance_metrics["preprocessing_used"] += 1
                    logger.info("Image preprocessing applied")
                except Exception as e:
                    logger.warning(f"Image preprocessing failed: {e}")

            # Use Aya:8b for all receipt analysis
            model = "aya:8b"

            # Utwórz zoptymalizowany prompt do analizy paragonu
            prompt = f"""Analizujesz polski paragon i zwracasz TYLKO poprawny JSON. Instrukcje:

## KRYTYCZNE ZASADY:
1. Zwracaj WYŁĄCZNIE JSON - żadnego tekstu przed ani po
2. Używaj podwójnych cudzysłowów dla stringów
3. Liczby jako float (bez cudzysłowów)
4. Daty YYYY-MM-DD
5. Pomiń metadane (PTU, SUMA, NIP, RABAT)

## NORMALIZACJA:
- Sklepy: "LIDL POLSKA" → "Lidl", "BIEDRONKA SP Z O.O." → "Biedronka"
- Produkty: wielkie litery bez błędów OCR
- Ceny: "2,99" → 2.99, "3.50" → 3.5

## BŁĘDY OCR - POPRAW:
- "KawZiarD orBar" → "KAWA ZIARNISTA DORBAR"
- "tnipsylopSolone" → "CHIPSY TOP SOLONE"  
- "PicrozkiGyoza" → "PIEROGI GYOZA"
- "Skyrplinynatural" → "SKYR PŁYNNY NATURALNY"
- "Czukoliwlab.orzech" → "CZEKOLADA Z ORZECHAMI"
- "Noklarbanan" → "NAKŁADKA BANAN"
- "Bananyluz" → "BANAN LUZ"

## PRZYKŁADY PRAWIDŁOWYCH JSON:

**Biedronka z wagą:**
{{"store":"Biedronka","address":"ul. Kolejowa 15","date":"2024-01-16","items":[{{"name":"JOGURT NATURALNY","quantity":2.0,"unit_price":1.99,"total_price":3.98,"tax_category":"A"}},{{"name":"BANANY","quantity":0.5,"unit_price":4.99,"total_price":2.50,"tax_category":"B"}}],"total":6.48}}

**Lidl z błędami OCR:**
{{"store":"Lidl","address":"","date":"2024-01-15","items":[{{"name":"PIEROGI GYOZA","quantity":1.0,"unit_price":4.9,"total_price":4.9,"tax_category":"A"}},{{"name":"CZEKOLADA Z ORZECHAMI","quantity":1.0,"unit_price":0.9,"total_price":0.9,"tax_category":"B"}},{{"name":"NAKŁADKA BANAN","quantity":1.0,"unit_price":12.9,"total_price":12.9,"tax_category":"A"}},{{"name":"BANAN LUZ","quantity":1.0,"unit_price":0.7,"total_price":0.7,"tax_category":"B"}}],"total":19.4}}

**Kaufland z rabatem:**
{{"store":"Kaufland","address":"","date":"2024-01-21","items":[{{"name":"MĄKA PSZENNA","quantity":1.0,"unit_price":2.29,"total_price":2.29,"tax_category":"A"}},{{"name":"MLEKO 3.2%","quantity":1.0,"unit_price":3.49,"total_price":3.49,"tax_category":"B"}}],"discounts":[{{"description":"RABAT","amount":0.30}}],"total":5.48}}

**Tesco z jednostkami:**
{{"store":"Tesco","address":"ul. Handlowa 5","date":"2024-02-10","items":[{{"name":"POMIDORY","quantity":2.5,"unit_price":3.99,"total_price":9.98,"tax_category":"A"}},{{"name":"WODA MINERALNA 1.5L","quantity":3.0,"unit_price":1.49,"total_price":4.47,"tax_category":"B"}},{{"name":"CHIPSY PAPRYKA 150G","quantity":1.0,"unit_price":4.99,"total_price":4.99,"tax_category":"A"}}],"total":19.44}}

**Żabka z czasem:**
{{"store":"Żabka","address":"ul. Główna 10","date":"2024-03-15","time":"14:30","items":[{{"name":"COCA COLA 0.5L","quantity":1.0,"unit_price":3.49,"total_price":3.49,"tax_category":"B"}},{{"name":"HOT DOG","quantity":1.0,"unit_price":5.99,"total_price":5.99,"tax_category":"A"}}],"total":9.48}}

**Carrefour z długim adresem:**
{{"store":"Carrefour","address":"Al. Jerozolimskie 148, 02-326 Warszawa","date":"2024-04-20","items":[{{"name":"CHLEB RAZOWY 500G","quantity":1.0,"unit_price":2.79,"total_price":2.79,"tax_category":"A"}},{{"name":"MASŁO EXTRA 200G","quantity":2.0,"unit_price":4.29,"total_price":8.58,"tax_category":"B"}},{{"name":"MLEKO UHT 3.2% 1L","quantity":1.0,"unit_price":2.99,"total_price":2.99,"tax_category":"B"}}],"total":14.36}}

## WYMAGANY SCHEMAT:
{{"store":"string","address":"string","date":"YYYY-MM-DD","time":"HH:MM","items":[{{"name":"string","quantity":float,"unit_price":float,"total_price":float,"tax_category":"A|B|C"}}],"discounts":[{{"description":"string","amount":float}}],"total":float}}

TEKST PARAGONU:
{ocr_text}

ZWRÓĆ TYLKO JSON:

            # Wywołaj LLM do analizy z timeout
            response = await timeout_manager.run_with_timeout(
                hybrid_llm_client.chat(
                    model=model,
                    messages=[
                        {
                            "role": "system",
                            "content": "Jesteś specjalistycznym asystentem do analizy paragonów z polskich sklepów. Wyciągnij strukturalne dane z tekstu paragonu.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    stream=False,
                ),
                timeout=TimeoutConfig.AI_ANALYSIS_TIMEOUT,
                operation="llm_receipt_analysis",
            )

            # Obsługa odpowiedzi: tylko dict, nie AsyncGenerator
            if not isinstance(response, dict) or "message" not in response:
                logger.warning("LLM nie zwrócił odpowiedzi, używam fallback parser")
                # Fallback do prostszego parsowania
                receipt_data = self._fallback_parse(ocr_text)
            else:
                # Parsuj odpowiedź LLM aby wyciągnąć strukturalne dane
                content = response["message"]["content"]
                receipt_data = self._parse_llm_response(content)

                # Jeśli _parse_llm_response zwrócił None lub pusty dict, użyj fallback parsera
                if receipt_data is None or not receipt_data:
                    logger.warning(
                        "LLM odpowiedź nie zawierała JSON lub jest pusta, używam fallback parser"
                    )
                    receipt_data = self._fallback_parse(ocr_text)

        except Exception as e:
            logger.error(f"Error in receipt analysis: {e}")
            processing_time = time.time() - start_time
            self._update_performance_metrics(processing_time)

            return AgentResponse(
                success=False,
                error=str(e),
                text=f"Przepraszam, wystąpił błąd podczas analizy paragonu: {e}",
                metadata={"processing_time": processing_time},
            )

        # Waliduj i popraw wyciągnięte dane
        receipt_data = self._validate_and_fix_data(receipt_data)

        # Enhanced validation with business logic
        is_valid, validation_errors, validated_data = (
            receipt_validator.validate_receipt_data(receipt_data)
        )

        if not is_valid:
            logger.warning(f"Receipt validation failed: {validation_errors}")
            # Continue with original data but log warnings
            for error in validation_errors:
                logger.warning(f"Validation error: {error}")
        else:
            receipt_data = validated_data
            logger.info("Receipt data validation successful")

        # Step 3: Czyszczenie i deuplikacja produktów
        if receipt_data.get("items"):
            original_count = len(receipt_data["items"])
            receipt_data["items"] = self._clean_and_deduplicate_items(
                receipt_data["items"]
            )
            cleaned_count = len(receipt_data["items"])
            logger.info(f"Oczyszczono produkty: {original_count} → {cleaned_count}")

        # Step 4: Walidacja matematyczna z poprawką sumy
        if receipt_data.get("items") and receipt_data.get("total_amount"):
            calculated_total, is_valid = ocr_processor.validate_calculations(
                receipt_data["items"], receipt_data["total_amount"]
            )

            if not is_valid:
                logger.warning(
                    f"Błąd walidacji matematycznej: obliczona suma {calculated_total:.2f}, "
                    f"z paragonu {receipt_data['total_amount']:.2f}"
                )
                # Użyj obliczonej sumy jako prawdziwej
                receipt_data["total_amount"] = calculated_total
                logger.info(f"Poprawiono sumę na {calculated_total:.2f}")
            else:
                logger.info("Walidacja matematyczna poprawna")

        # Extract store information
        store_info = normalize_store_name(ocr_text)

        # Use normalized store information
        store_name = store_info.get("normalized_name", "Nieznany sklep")
        store_chain = store_info.get("chain", "Unknown")
        store_type = store_info.get("type", "unknown")
        store_confidence = store_info.get("confidence", 0.0)
        store_method = store_info.get("method", "unknown")

        # Update receipt_data with enhanced store information
        receipt_data["store_name"] = store_name
        receipt_data["normalized_store_name"] = store_name
        receipt_data["normalized_store_name_en"] = self._get_english_store_name(
            store_name
        )
        receipt_data["store_chain"] = store_chain
        receipt_data["store_type"] = store_type
        receipt_data["store_confidence"] = store_confidence
        receipt_data["store_normalization_method"] = store_method
        receipt_data["store_normalizer"] = "enhanced"

        # Log warning if confidence is low but continue processing
        if store_confidence < 0.5:
            log_failed_extraction(
                file_path="unknown",
                ocr_text=ocr_text,
                analysis_result=receipt_data,
                error_type="low_store_confidence",
                error_details=f"Store confidence too low: {store_confidence}",
                confidence_score=store_confidence,
                suggested_improvements=[
                    "Improve store name detection",
                    "Add more store patterns",
                ],
            )
            # Continue with processing but add warning
            receipt_data["store_warning"] = f"Store confidence low: {store_confidence}"

        # Update performance metrics
        processing_time = time.time() - start_time
        self._update_performance_metrics(processing_time)

        # Add total_amount to receipt_data for consistency
        receipt_data["total_amount"] = receipt_data.get("total", 0.0)
        # If total is 0 but we have items, calculate total from items
        if receipt_data["total_amount"] == 0.0 and receipt_data.get("items"):
            calculated_total = sum(item.get("total_price", 0) for item in receipt_data["items"])
            receipt_data["total_amount"] = calculated_total
            receipt_data["total"] = calculated_total

        # Return successful response
        return AgentResponse(
            success=True,
            text="Paragon został pomyślnie przeanalizowany",
            data=receipt_data,
            metadata={
                "processing_time": processing_time,
                "store_confidence": store_confidence,
                "items_count": len(receipt_data.get("items", [])),
                "total_amount": receipt_data.get("total", 0.0)
            }
        )

    def _get_english_store_name(self, polish_name: str) -> str:
        """Translate Polish store name to English"""
        translations = {
            "Lidl": "Lidl",
            "Biedronka": "Biedronka",
            "Kaufland": "Kaufland",
            "Tesco": "Tesco",
            "Carrefour": "Carrefour",
            "Auchan": "Auchan",
            "Żabka": "Zabka",
            "Netto": "Netto",
            "Aldi": "Aldi",
            "Penny": "Penny",
            "Intermarché": "Intermarché",
            "Spar": "Spar",
            "Dino": "Dino",
            "Stokrotka": "Stokrotka",
            "ABC": "ABC",
            "Delikatesy": "Delicatessen",
            "Groszek": "Groszek",
            "Bomi": "Bomi",
            "PoloMarket": "PoloMarket",
            "Lewiatan": "Lewiatan",
            "Nieznany sklep": "Unknown store",
        }
        return translations.get(polish_name, polish_name)

    def _normalize_store_name(self, receipt_data: dict[str, Any]) -> None:
        """Normalizuje nazwę sklepu z paragonu przy użyciu adaptera"""
        store_name = receipt_data.get("store_name", "")

        # Jeśli brak nazwy sklepu, spróbuj wykryć z wzorców
        if not store_name or store_name.lower() == "nieznany sklep":
            detected_store = self._detect_store_from_patterns(receipt_data)
            if detected_store:
                store_name = detected_store
                receipt_data["store_name"] = detected_store
                logger.info(f"Wykryto sklep z wzorców: {detected_store}")

        if store_name:
            normalized_store = self.normalizer_adapter.normalize_store_name(
                store_name, method="auto"
            )
            receipt_data["normalized_store_name"] = normalized_store.get(
                "normalized_name", "Nieznany sklep"
            )
            receipt_data["normalized_store_name_en"] = normalized_store.get(
                "normalized_name_en", "Unknown store"
            )
            receipt_data["store_chain"] = normalized_store.get("chain", "Unknown")
            receipt_data["store_type"] = normalized_store.get("type", "unknown")
            receipt_data["store_confidence"] = normalized_store.get("confidence", 0.0)
            receipt_data["store_normalization_method"] = normalized_store.get(
                "method", "unknown"
            )
            receipt_data["store_normalizer"] = normalized_store.get(
                "normalizer", "adapter"
            )
            logger.info(
                f"Znormalizowano nazwę sklepu: {store_name} -> {normalized_store.get('normalized_name', 'Nieznany sklep')} (confidence: {normalized_store.get('confidence', 0.0)})"
            )
        else:
            receipt_data["normalized_store_name"] = "Nieznany sklep"
            receipt_data["normalized_store_name_en"] = "Unknown store"
            receipt_data["store_chain"] = "Unknown"
            receipt_data["store_type"] = "unknown"
            receipt_data["store_confidence"] = 0.0
            receipt_data["store_normalization_method"] = "no_store_name"
            receipt_data["store_normalizer"] = "adapter"

    def _normalize_product_names(self, items: list[dict[str, Any]]) -> None:
        """Normalizuje nazwy produktów z paragonu przy użyciu adaptera"""
        if not items:
            return
        try:
            normalized_items = []
            for item in items:
                name = item.get("name", "")
                norm = self.normalizer_adapter.normalize_product_name(
                    name, method="auto"
                )
                item["original_name"] = norm.get("original", name)
                item["normalized_name"] = norm.get("normalized", name)
                item["product_category"] = norm.get("category", "unknown")
                item["normalization_confidence"] = norm.get("confidence", 0.0)
                item["normalization_method"] = norm.get("method", "unknown")
                item["normalizer"] = norm.get("normalizer", "adapter")
                normalized_items.append(item)
            items.clear()
            items.extend(normalized_items)
            stats = None
            with contextlib.suppress(Exception):
                stats = self.normalizer_adapter.get_statistics()
            logger.info(f"Statystyki normalizacji nazw produktów: {stats}")
        except Exception as e:
            logger.error(f"Błąd podczas normalizacji nazw produktów: {e}")
            for item in items:
                if "name" in item:
                    item["original_name"] = item["name"]
                    item["normalized_name"] = item["name"]
                    item["product_category"] = "unknown"
                    item["normalization_confidence"] = 0.0
                    item["normalization_method"] = "error"

    def _detect_store_from_patterns(self, receipt_data: dict[str, Any]) -> str | None:
        """
        Wykrywa sklep na podstawie wzorców w danych paragonu.

        Args:
            receipt_data: Dane paragonu

        Returns:
            Nazwa sklepu lub None jeśli nie wykryto
        """
        # Sprawdź wzorce w nazwach produktów
        items = receipt_data.get("items", [])
        product_names = " ".join([item.get("name", "") for item in items]).lower()

        # Wzorce charakterystyczne dla sklepów
        store_patterns = {
            "Lidl": [
                "pestogustobel",
                "dorbar",
                "licll",
                "lidl",
                "kawziard",
                "makarconch",
            ],
            "Biedronka": ["biedronka", "k.jaja", "k.makaron", "k.bita"],
            "Kaufland": ["kaufland", "jamar", "passata"],
            "Tesco": ["tesco"],
        }

        for store, patterns in store_patterns.items():
            for pattern in patterns:
                if pattern in product_names:
                    logger.info(
                        f"Wykryto sklep {store} na podstawie wzorca '{pattern}'"
                    )
                    return store

        return None

    def _create_receipt_analysis_prompt(self, ocr_text: str) -> str:
        """Tworzy zoptymalizowany prompt dla LLM do analizy polskich paragonów z few-shot examples"""

        system_prompt = """Jesteś ekspertem od analizy polskich paragonów. Analizuj tekst paragonu i wyciągnij strukturalne dane.

INSTRUKCJE:
1. Zawsze zwracaj poprawny JSON
2. Nazwy sklepów normalizuj: "LIDL POLSKA" -> "Lidl", "BIEDRONKA SP Z O.O." -> "Biedronka"
3. Produkty z wielkiej litery: "chleb żytni" -> "CHLEB ŻYTNI"
4. Ceny jako float: "2,99" -> 2.99
5. Daty w formacie YYYY-MM-DD
6. Jeśli brak danych, użyj null lub ""
7. Oblicz total_price = quantity * unit_price
8. Sprawdź czy suma się zgadza
9. Filtruj tylko prawdziwe produkty, pomiń "Rabat", "PTU", "Suma PLN"
10. Popraw błędy OCR: "KawZiarD orBar" -> "KawZiarDorBar", "tnipsylopSolone" -> "ChipsyTopSolone"

PRZYKŁADY:

PRZYKŁAD 1 - Biedronka:
Tekst: "BIEDRONKA SP Z O.O.\nul. Kolejowa 15\n2x JOGURT NATURALNY\n1,99\n3,98 A\nBANANY\n0,5 kg\n4,99\n2,50 B\nSUMA 6,48\n16.01.2024"
JSON: {"store": "Biedronka", "address": "ul. Kolejowa 15", "date": "2024-01-16", "items": [{"name": "JOGURT NATURALNY", "quantity": 2.0, "unit_price": 1.99, "total_price": 3.98, "tax_category": "A"}, {"name": "BANANY", "quantity": 0.5, "unit_price": 4.99, "total_price": 2.50, "tax_category": "B"}], "total": 6.48}

PRZYKŁAD 2 - Lidl:
Tekst: "LIDL POLSKA SP Z O.O.\nul. Magazynowa 2, 01-123 Warszawa\nNIP: 123-456-78-90\nCHLEB ŻYTNI\n2,99 A\nMASŁO EXTRA\n4,50 B\nSUMA PLN 7,49\nData: 15.01.2024 14:30"
JSON: {"store": "Lidl", "address": "ul. Magazynowa 2, 01-123 Warszawa", "date": "2024-01-15", "items": [{"name": "CHLEB ŻYTNI", "quantity": 1.0, "unit_price": 2.99, "total_price": 2.99, "tax_category": "A"}, {"name": "MASŁO EXTRA", "quantity": 1.0, "unit_price": 4.50, "total_price": 4.50, "tax_category": "B"}], "total": 7.49}

PRZYKŁAD 3 - Kaufland z błędami OCR:
Tekst: "KAUFLAND\nMĄKA PSZENNA\n2,29 A\nRABAT -0,30\nMLEKO 3,2%\n3,49 B\nKawZiarD orBar500g\n4,99 A\ntnipsylopSolonel5Ug\n3,99 B\nSUMA 13,46\n17.01.2024"
JSON: {"store": "Kaufland", "address": "", "date": "2024-01-17", "items": [{"name": "MĄKA PSZENNA", "quantity": 1.0, "unit_price": 2.29, "total_price": 2.29, "tax_category": "A"}, {"name": "MLEKO 3,2%", "quantity": 1.0, "unit_price": 3.49, "total_price": 3.49, "tax_category": "B"}, {"name": "KawZiarDorBar500g", "quantity": 1.0, "unit_price": 4.99, "total_price": 4.99, "tax_category": "A"}, {"name": "ChipsyTopSolone150g", "quantity": 1.0, "unit_price": 3.99, "total_price": 3.99, "tax_category": "B"}], "discounts": [{"description": "RABAT", "amount": 0.30}], "total": 13.46}

PRZYKŁAD 4 - Tesco z różnymi jednostkami:
Tekst: "TESCO POLSKA\nPOMIDORY\n2,50 kg\n3,99\n9,98 A\nWODA MINERALNA\n1,5 l\n2,99\n4,49 B\nCHIPSY PAPRYKA\n150 g\n4,99 A\nSUMA 19,46\n18.01.2024"
JSON: {"store": "Tesco", "address": "", "date": "2024-01-18", "items": [{"name": "POMIDORY", "quantity": 2.5, "unit_price": 3.99, "total_price": 9.98, "tax_category": "A"}, {"name": "WODA MINERALNA", "quantity": 1.5, "unit_price": 2.99, "total_price": 4.49, "tax_category": "B"}, {"name": "CHIPSY PAPRYKA", "quantity": 0.15, "unit_price": 4.99, "total_price": 4.99, "tax_category": "A"}], "total": 19.46}

WYMAGANY FORMAT JSON:
{
  "store": "string",
  "address": "string",
  "date": "YYYY-MM-DD",
  "time": "HH:MM",
  "items": [
    {
      "name": "string",
      "quantity": float,
      "unit_price": float,
      "total_price": float,
      "tax_category": "A|B|C"
    }
  ],
  "discounts": [{"description": "string", "amount": float}],
  "total": float
}"""

        user_prompt = f"""Analizuj poniższy tekst paragonu i zwróć TYLKO poprawny JSON zgodnie z przykładami.
Pamiętaj o poprawkach błędów OCR i filtrowaniu tylko prawdziwych produktów:

{ocr_text}

JSON:"""

        return f"{system_prompt}\n\n{user_prompt}"

    def _update_performance_metrics(self, processing_time: float):
        """
        Aktualizuje metryki wydajności agenta.
        """
        self.performance_metrics["total_receipts"] += 1

        # Aktualizuj średni czas przetwarzania
        current_avg = self.performance_metrics["average_processing_time"]
        total_receipts = self.performance_metrics["total_receipts"]
        self.performance_metrics["average_processing_time"] = (
            current_avg * (total_receipts - 1) + processing_time
        ) / total_receipts

    def get_performance_metrics(self) -> dict[str, Any]:
        """
        Zwraca metryki wydajności agenta.
        """
        return {
            **self.performance_metrics,
            "batch_processing_rate": (
                self.performance_metrics["batch_processed"]
                / max(self.performance_metrics["total_receipts"], 1)
            ),
            "preprocessing_rate": (
                self.performance_metrics["preprocessing_used"]
                / max(self.performance_metrics["total_receipts"], 1)
            ),
        }

    def _normalize_date(self, date_str: str) -> str:
        """Normalizuje format daty do YYYY-MM-DD z zaawansowaną walidacją"""
        import re
        from datetime import datetime, timedelta
        
        if not date_str:
            return datetime.now().strftime("%Y-%m-%d")
            
        # Próbuj różne formaty dat z walidacją
        patterns = [
            r'(\d{2})\.(\d{2})\.(\d{4})',  # DD.MM.YYYY
            r'(\d{4})-(\d{2})-(\d{2})',   # YYYY-MM-DD
            r'(\d{2})/(\d{2})/(\d{4})',   # DD/MM/YYYY
            r'(\d{2})-(\d{2})-(\d{4})',   # DD-MM-YYYY
            r'(\d{1,2})\.(\d{1,2})\.(\d{2})',  # D.M.YY lub DD.MM.YY
            r'(\d{1,2})/(\d{1,2})/(\d{2})',    # D/M/YY lub DD/MM/YY
        ]
        
        for pattern in patterns:
            match = re.search(pattern, date_str)
            if match:
                groups = match.groups()
                
                try:
                    if pattern == patterns[0] or pattern == patterns[2] or pattern == patterns[3]:
                        # DD.MM.YYYY, DD/MM/YYYY, DD-MM-YYYY
                        day, month, year = groups
                        day, month, year = int(day), int(month), int(year)
                    elif pattern == patterns[1]:
                        # YYYY-MM-DD
                        year, month, day = groups
                        day, month, year = int(day), int(month), int(year)
                    else:
                        # DD.MM.YY lub DD/MM/YY
                        day, month, year = groups
                        day, month, year = int(day), int(month), int(year)
                        # Konwertuj 2-cyfrowy rok na 4-cyfrowy
                        if year < 50:
                            year += 2000
                        elif year < 100:
                            year += 1900
                    
                    # Walidacja zakresu dat
                    if not self._is_valid_date_range(year, month, day):
                        continue
                        
                    return f"{year:04d}-{month:02d}-{day:02d}"
                    
                except ValueError:
                    continue
        
        # Fallback - spróbuj parsować z datetime z walidacją
        try:
            for fmt in ["%d.%m.%Y", "%Y-%m-%d", "%d/%m/%Y", "%d-%m-%Y", "%d.%m.%y", "%d/%m/%y"]:
                try:
                    parsed_date = datetime.strptime(date_str, fmt)
                    
                    # Walidacja zakresu dat
                    if self._is_valid_receipt_date(parsed_date):
                        return parsed_date.strftime("%Y-%m-%d")
                except ValueError:
                    continue
        except Exception:
            pass
            
        return datetime.now().strftime("%Y-%m-%d")
    
    def _is_valid_date_range(self, year: int, month: int, day: int) -> bool:
        """Sprawdza czy data jest w poprawnym zakresie"""
        try:
            # Sprawdź podstawowe zakresy
            if not (1 <= month <= 12):
                return False
            if not (1 <= day <= 31):
                return False
            if not (1900 <= year <= 2100):
                return False
                
            # Sprawdź czy data jest poprawna (uwzględnia lata przestępne)
            test_date = datetime(year, month, day)
            
            # Sprawdź czy data nie jest z przyszłości (+ 1 dzień tolerancji)
            tomorrow = datetime.now() + timedelta(days=1)
            if test_date > tomorrow:
                return False
                
            # Sprawdź czy data nie jest starsza niż 10 lat
            ten_years_ago = datetime.now() - timedelta(days=3650)
            if test_date < ten_years_ago:
                return False
                
            return True
            
        except ValueError:
            return False
    
    def _is_valid_receipt_date(self, date_obj: datetime) -> bool:
        """Sprawdza czy data paragonu jest rozsądna"""
        now = datetime.now()
        
        # Nie może być z przyszłości (+ 1 dzień tolerancji)
        if date_obj > now + timedelta(days=1):
            return False
            
        # Nie może być starsza niż 10 lat
        if date_obj < now - timedelta(days=3650):
            return False
            
        return True
    
    def _normalize_price(self, price_value: Any) -> float:
        """Normalizuje cenę do float"""
        if isinstance(price_value, (int, float)):
            return float(price_value)
            
        if isinstance(price_value, str):
            import re
            # Wyodrębnij liczby z przecinkami/kropkami
            price_match = re.search(r'\d+[,\.]\d{2}', price_value)
            if price_match:
                return float(price_match.group().replace(',', '.'))
            
            # Próbuj znaleźć tylko liczby
            numbers = re.findall(r'\d+', price_value)
            if numbers:
                return float(numbers[0])
                
        return 0.0

    def _validate_and_fix_data(self, receipt_data: dict[str, Any]) -> dict[str, Any]:
        """Waliduje i naprawia wyciągnięte dane"""
        if not receipt_data or not isinstance(receipt_data, dict):
            logger.warning("Brak danych do walidacji")
            return {}
            
        # Podstawowa walidacja i naprawy
        validated_data = receipt_data.copy()
        
        # Napraw format daty
        if "date" in validated_data:
            date_str = str(validated_data["date"])
            validated_data["date"] = self._normalize_date(date_str)
        
        # Napraw ceny
        if "total" in validated_data:
            validated_data["total"] = self._normalize_price(validated_data["total"])
            
        # Napraw ceny produktów
        if "items" in validated_data and isinstance(validated_data["items"], list):
            for item in validated_data["items"]:
                if isinstance(item, dict):
                    if "unit_price" in item:
                        item["unit_price"] = self._normalize_price(item["unit_price"])
                    if "total_price" in item:
                        item["total_price"] = self._normalize_price(item["total_price"])
                    if "quantity" in item:
                        try:
                            item["quantity"] = float(item["quantity"])
                        except (ValueError, TypeError):
                            item["quantity"] = 1.0
                            
        # Napraw rabaty
        if "discounts" in validated_data and isinstance(validated_data["discounts"], list):
            for discount in validated_data["discounts"]:
                if isinstance(discount, dict) and "amount" in discount:
                    discount["amount"] = self._normalize_price(discount["amount"])
                    
        logger.info("Dane paragonu zwalidowane i naprawione")
        return validated_data
    
    def _fallback_parse(self, ocr_text: str) -> dict[str, Any]:
        """Zoptymalizowany parser fallback z lepszą ekstrakcją produktów"""
        fallback_data = {
            "store": "Nieznany sklep",
            "store_name": "Nieznany sklep", 
            "address": "",
            "date": self._normalize_date(""),
            "time": "",
            "items": [],
            "discounts": [],
            "total": 0.0
        }
        
        if not ocr_text:
            return fallback_data
            
        import re
        lines = ocr_text.strip().split('\n')
        
        # Ulepszone wzorce dla ekstraktji produktów z cenami
        enhanced_product_patterns = [
            # Format: NAZWA ILOŚĆ CENA SUMA (np. "JOGURT 2x 1.99 3.98")
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s\d\.%]+?)\s+(\d+(?:\.\d+)?)\s*x\s+(\d+[,\.]\d{2})\s+(\d+[,\.]\d{2})',
            # Format: NAZWA CENA TAX (np. "MLEKO 3.49 B")
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s\d\.%]{3,}?)\s+(\d+[,\.]\d{2})\s*([ABC])',
            # Format: NAZWA WAGA CENA/KG SUMA (np. "BANANY 0.5kg 4.99 2.50")
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s\d\.%]+?)\s+(\d+[,\.]\d+)\s*kg\s+(\d+[,\.]\d{2})\s+(\d+[,\.]\d{2})',
            # Format: NAZWA CENA PLN (np. "CHLEB 2.99 PLN")
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s\d\.%]{3,}?)\s+(\d+[,\.]\d{2})\s*PLN',
            # Format: NAZWA CENA (podstawowy, bez dodatkowych oznaczeń)
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s\d\.%]{4,}?)\s+(\d+[,\.]\d{2})(?=\s|$)',
        ]
        
        # Rozszerzona lista znanych produktów z testów OCR
        known_ocr_products = {
            "PicrozkiGyoza": "PIEROGI GYOZA",
            "Skyrplinynatural": "SKYR PŁYNNY NATURALNY", 
            "Czukoliwlab.orzech": "CZEKOLADA Z ORZECHAMI",
            "krakerzyDobryChrup": "KRAKERSY DOBRY CHRUP",
            "Noklarbanan": "NAKŁADKA BANAN",
            "Bananyluz": "BANAN LUZ",
            "KawZiarDorBar": "KAWA ZIARNISTA DORBAR",
            "tnipsylopSolone": "CHIPSY TOP SOLONE",
            "FrytkiKarbmrpot": "FRYTKI KARBOWANE MROŻONE",
            "JogurtNaturalny": "JOGURT NATURALNY",
            "MasłoExtra": "MASŁO EXTRA",
            "MlekoUHT": "MLEKO UHT",
            "ChlebŻytni": "CHLEB ŻYTNI",
            "PomidoryMalinowe": "POMIDORY MALINOWE",
            "WodaMineralna": "WODA MINERALNA"
        }
        
        # Przeszukaj wszystkie linie tekstu
        all_text = ' '.join(lines)
        
        # Wykryj sklep z rozszerzonymi wzorcami i obsługą błędów OCR
        store_patterns = {
            # Lidl - różne warianty OCR
            r'LIDL.*?(?:POLSKA|SP|Z\.?O\.?O\.?|LICLL|LICIL)': 'Lidl',
            r'LICLL.*?(?:SP|Z\.?O\.?O\.?|POLSKA)': 'Lidl',
            r'L[I1]DL.*?POLSKA': 'Lidl',
            
            # Biedronka - różne warianty
            r'BIEDRONKA.*?(?:SP|Z\.?O\.?O\.?)': 'Biedronka', 
            r'B[I1]EDRONKA': 'Biedronka',
            r'BIEDR0NKA': 'Biedronka',  # zero zamiast O
            
            # Kaufland - warianty OCR
            r'KAUFLAND.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Kaufland',
            r'KAUF[L1]AND': 'Kaufland',
            r'KAUFI?AND': 'Kaufland',
            
            # Tesco - warianty
            r'TESCO.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Tesco',
            r'T[E3]SCO': 'Tesco',
            
            # Carrefour - warianty francuski/polski
            r'CARREFOUR.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Carrefour',
            r'CARR[E3]FOUR': 'Carrefour',
            r'CARREF0UR': 'Carrefour',  # zero zamiast O
            
            # Auchan - warianty francuski
            r'AUCHAN.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Auchan',
            r'AUCH[A4]N': 'Auchan',
            
            # Żabka - małe sklepy
            r'ŻABKA.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Żabka',
            r'ZABKA': 'Żabka',  # bez polskich znaków
            r'Ż[A4]BKA': 'Żabka',
            
            # Netto - dyskont
            r'NETTO.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Netto',
            r'N[E3]TTO': 'Netto',
            r'NETT0': 'Netto',  # zero zamiast O
            
            # Aldi - dyskont niemiecki
            r'ALDI.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Aldi',
            r'A[L1]DI': 'Aldi',
            r'ALD1': 'Aldi',  # jedna zamiast I
            
            # Penny - dyskont
            r'PENNY.*?(?:MARKET|POLSKA|SP|Z\.?O\.?O\.?)?': 'Penny',
            r'P[E3]NNY': 'Penny',
            r'PENNV': 'Penny',  # V zamiast Y
            
            # Spar - mniejsza sieć
            r'SPAR.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Spar',
            r'SP[A4]R': 'Spar',
            
            # Lewiatan - lokalna sieć
            r'LEWIATAN.*?(?:SP|Z\.?O\.?O\.?)?': 'Lewiatan',
            r'L[E3]WIATAN': 'Lewiatan',
            r'LEW[I1]ATAN': 'Lewiatan',
            
            # PoloMarket - sieć regionalna
            r'POLO.*?MARKET': 'PoloMarket',
            r'P0L0.*?MARKET': 'PoloMarket',  # zera zamiast O
            r'POLO.*?MARK[E3]T': 'PoloMarket',
            
            # Groszek - sieć regionalna
            r'GROSZEK.*?(?:SP|Z\.?O\.?O\.?)?': 'Groszek',
            r'GR0SZEK': 'Groszek',  # zero zamiast O
            r'GROSZ[E3]K': 'Groszek',
            
            # Stokrotka - sieć regionalna
            r'STOKROTKA.*?(?:SP|Z\.?O\.?O\.?)?': 'Stokrotka',
            r'ST0KR0TKA': 'Stokrotka',  # zera zamiast O
            r'STOKR0TKA': 'Stokrotka',
            
            # Dino - dyskont
            r'DINO.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Dino',
            r'D[I1]NO': 'Dino',
            r'DIN0': 'Dino',  # zero zamiast O
            
            # Intermarché - francuska sieć
            r'INTERMARCHÉ.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Intermarché',
            r'INTERMARCHE': 'Intermarché',  # bez akcentu
            r'INT[E3]RMARCHÉ': 'Intermarché',
            
            # Leclerc - francuska sieć
            r'LECLERC.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Leclerc',
            r'L[E3]CLERC': 'Leclerc',
            r'LECL[E3]RC': 'Leclerc',
            
            # Castorama - sklepy budowlane
            r'CASTORAMA.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Castorama',
            r'CAST0RAMA': 'Castorama',  # zero zamiast O
            r'CASTOR[A4]MA': 'Castorama',
            
            # Leroy Merlin - sklepy budowlane
            r'LEROY.*?MERLIN': 'Leroy Merlin',
            r'L[E3]ROY.*?M[E3]RLIN': 'Leroy Merlin',
            r'LEROV.*?MERLIN': 'Leroy Merlin',  # V zamiast Y
            
            # Medicover - apteki/medyczny
            r'MEDICOVER.*?(?:SP|Z\.?O\.?O\.?)?': 'Medicover',
            r'M[E3]DICOVER': 'Medicover',
            r'MEDIC0VER': 'Medicover',  # zero zamiast O
            
            # Rossmann - drogeria
            r'ROSSMANN.*?(?:POLSKA|SP|Z\.?O\.?O\.?)?': 'Rossmann',
            r'R0SSMANN': 'Rossmann',  # zero zamiast O
            r'ROSSM[A4]NN': 'Rossmann',
            
            # Hebe - drogeria
            r'HEBE.*?(?:SP|Z\.?O\.?O\.?)?': 'Hebe',
            r'H[E3]BE': 'Hebe',
            r'HEB3': 'Hebe',  # 3 zamiast E
        }
        
        for pattern, store in store_patterns.items():
            if re.search(pattern, all_text.upper(), re.IGNORECASE):
                fallback_data["store"] = store
                fallback_data["store_name"] = store
                break
                
        # Wykryj datę z ulepszonymi wzorcami
        date_patterns = [
            r'DATA[:\s]*(\d{4})-(\d{2})-(\d{2})',  # DATA: 2024-01-15
            r'(\d{2})\.(\d{2})\.(\d{4})',          # DD.MM.YYYY
            r'(\d{4})-(\d{2})-(\d{2})',            # YYYY-MM-DD
            r'(\d{2})/(\d{2})/(\d{4})',            # DD/MM/YYYY
            r'(\d{1,2})\.(\d{1,2})\.(\d{2})',      # D.M.YY lub DD.MM.YY
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, all_text)
            if match:
                groups = match.groups()
                if len(groups) == 3:
                    if 'DATA' in pattern:
                        year, month, day = groups
                        fallback_data["date"] = f"{year}-{month:0>2}-{day:0>2}"
                    elif pattern.endswith(r'(\d{2})'):  # YY format
                        day, month, year = groups
                        full_year = f"20{year}" if int(year) < 50 else f"19{year}"
                        fallback_data["date"] = f"{full_year}-{month:0>2}-{day:0>2}"
                    elif pattern.startswith(r'(\d{4})'):  # YYYY-MM-DD
                        year, month, day = groups
                        fallback_data["date"] = f"{year}-{month:0>2}-{day:0>2}"
                    else:  # DD.MM.YYYY lub DD/MM/YYYY
                        day, month, year = groups
                        fallback_data["date"] = f"{year}-{month:0>2}-{day:0>2}"
                break
        
        # Wykryj sumę z ulepszonymi wzorcami
        total_patterns = [
            r'(?:SUMA|RAZEM|TOTAL).*?(\d+[,\.]\d{2})',
            r'RAZEMPLN\s*(\d+[,\.]\d{2})',
            r'(?:DO\s+ZAPŁATY|ZAPŁACONO)\s*(\d+[,\.]\d{2})',
        ]
        
        for pattern in total_patterns:
            match = re.search(pattern, all_text.upper())
            if match:
                try:
                    fallback_data["total"] = float(match.group(1).replace(',', '.'))
                    break
                except ValueError:
                    continue
        
        # Ekstrakcja produktów - najpierw szukaj znanych wzorców OCR
        for ocr_product, clean_name in known_ocr_products.items():
            if ocr_product in all_text:
                # Znajdź cenę po produkcie
                product_index = all_text.find(ocr_product)
                after_product = all_text[product_index + len(ocr_product):]
                
                # Szukaj ceny w różnych formatach
                price_patterns = [
                    r'(\d+[,\.]\d{2})\s*(?:A|B|C)',  # Cena z kategorią podatkową
                    r'(\d+[,\.]\d{2})\s*PLN',        # Cena z PLN
                    r'(\d+[,\.]\d{2})',              # Sama cena
                ]
                
                for price_pattern in price_patterns:
                    price_match = re.search(price_pattern, after_product[:50])  # Szukaj w następnych 50 znakach
                    if price_match:
                        try:
                            price = float(price_match.group(1).replace(',', '.'))
                            if 0.01 <= price <= 1000:  # Rozsądny przedział cenowy
                                item = {
                                    "name": clean_name,
                                    "quantity": 1.0,
                                    "unit_price": price,
                                    "total_price": price,
                                    "tax_category": "A"
                                }
                                fallback_data["items"].append(item)
                                break
                        except ValueError:
                            continue
                    
        # Jeśli nie znaleziono produktów, użyj wzorców regex na całym tekście
        if not fallback_data["items"]:
            for pattern in enhanced_product_patterns:
                matches = re.finditer(pattern, all_text, re.IGNORECASE)
                for match in matches:
                    groups = match.groups()
                    try:
                        product_name = groups[0].strip()
                        
                        # Pomiń metadane
                        if self._is_metadata(product_name):
                            continue
                            
                        # Wyczyść nazwę produktu z błędów OCR
                        clean_name = self._clean_product_name_ocr(product_name)
                        if not clean_name or len(clean_name) < 3:
                            continue
                            
                        # Parsuj dane w zależności od wzorca
                        if len(groups) == 4:  # NAZWA ILOŚĆ CENA SUMA lub NAZWA WAGA CENA/KG SUMA
                            quantity = float(groups[1].replace(',', '.'))
                            unit_price = float(groups[2].replace(',', '.'))
                            total_price = float(groups[3].replace(',', '.'))
                        elif len(groups) == 3 and groups[2] in ['A', 'B', 'C']:  # NAZWA CENA TAX
                            quantity = 1.0
                            unit_price = float(groups[1].replace(',', '.'))
                            total_price = unit_price
                        else:  # NAZWA CENA
                            quantity = 1.0
                            unit_price = float(groups[1].replace(',', '.'))
                            total_price = unit_price
                            
                        # Sprawdź czy ceny są rozsądne
                        if 0.01 <= unit_price <= 1000 and 0.01 <= total_price <= 1000:
                            item = {
                                "name": clean_name,
                                "quantity": quantity,
                                "unit_price": unit_price,
                                "total_price": total_price,
                                "tax_category": groups[2] if len(groups) == 3 and groups[2] in ['A', 'B', 'C'] else "A"
                            }
                            fallback_data["items"].append(item)
                            
                    except (ValueError, IndexError):
                        continue
                        
        # Usuń duplikaty produktów
        seen_products = set()
        unique_items = []
        for item in fallback_data["items"]:
            product_key = item["name"].upper()
            if product_key not in seen_products:
                seen_products.add(product_key)
                unique_items.append(item)
        fallback_data["items"] = unique_items
        
        # Jeśli nie ma sumy, oblicz z produktów
        if fallback_data["total"] == 0.0 and fallback_data["items"]:
            calculated_total = sum(item.get("total_price", 0) for item in fallback_data["items"])
            fallback_data["total"] = round(calculated_total, 2)
            
        return fallback_data
    
    def _clean_product_name_ocr(self, product_name: str) -> str:
        """Czyści nazwę produktu z błędów OCR"""
        if not product_name:
            return ""
        
        # Usuń niepotrzebne znaki
        cleaned = product_name.strip()
        
        # Popraw typowe błędy OCR
        corrections = {
            "PicrozkiGyoza": "Pierogi Gyoza",
            "Skyrplinynatural": "Skyr płynny naturalny",
            "Czukoliwlab.orzech": "Czekolada z orzechami",
            "krakerzyDobryChrup": "Krakersy Dobry Chrup",
            "Noklarbanan": "Nakładka banan",
            "Bananyluz": "Banan luz",
            "Licllsp.z.0.0.sp.k.": "Lidl",
            "Reklamowkamalarec": "Reklamówka mała",
            "LidlPluskupon": "Lidl Plus kupon",
            "PTUA": "PTU A",
            "PTUC": "PTU C",
            "KvolaA": "Kola A",
            "kwjataC": "Kwota C",
            "Sunia": "Suma",
            "Razem": "Razem",
            "RAZEMPLN": "RAZEM PLN",
            "blalnosc": "Białkość",
            "Karlaplalniczab": "Karta płatnicza"
        }
        
        for wrong, correct in corrections.items():
            if wrong in cleaned:
                cleaned = cleaned.replace(wrong, correct)
        
        # Usuń liczby na końcu nazwy produktu
        cleaned = re.sub(r'\d+$', '', cleaned)
        
        # Usuń pojedyncze litery na końcu
        cleaned = re.sub(r'\s[A-Z]\s*$', '', cleaned)
        
        return cleaned.strip()
    
    def _is_metadata(self, text: str) -> bool:
        """Sprawdza czy tekst to metadane, nie nazwa produktu"""
        if not text:
            return True
        
        text_upper = text.upper()
        
        # Lista słów kluczowych metadanych
        metadata_keywords = [
            'PTU', 'SUMA', 'RAZEM', 'PLN', 'TOTAL', 'DATA', 'NIP', 'ADRES',
            'KARTA', 'PŁATNICZA', 'BŁAŁKOŚĆ', 'KWOTA', 'SUNIA', 'RAZEMPLN',
            'BG', 'NR', 'BLAŁNOSC', 'KARLAPLALNICZAB', 'ABYZAR', 'TAMOWO',
            'POCGORNE', 'VZEEWLIDL', 'JANKOWICE', 'POZNANSKA', 'LIDLPLUSKUPON',
            'REKLAMOWKA', 'MALAREC', 'OBG', 'SG', 'KVO', 'KWJATA', 'SUNIA'
        ]
        
        # Sprawdź czy tekst zawiera słowa kluczowe metadanych
        for keyword in metadata_keywords:
            if keyword in text_upper:
                return True
        
        # Sprawdź czy tekst to tylko liczby i znaki specjalne
        if re.match(r'^[\d\s\.\-]+$', text):
            return True
        
        # Sprawdź czy tekst jest za krótki (mniej niż 3 znaki)
        if len(text.strip()) < 3:
            return True
        
        return False
    
    def _clean_and_deduplicate_items(self, items: list[dict[str, Any]]) -> list[dict[str, Any]]:
        """Czyści i deduplikuje produkty"""
        if not items or not isinstance(items, list):
            return []
            
        cleaned_items = []
        seen_items = set()
        
        for item in items:
            if not isinstance(item, dict) or not item.get("name"):
                continue
                
            # Normalizuj nazwę dla porównania
            normalized_name = item["name"].strip().upper()
            
            if normalized_name not in seen_items:
                seen_items.add(normalized_name)
                
                # Wyczyść dane produktu
                cleaned_item = {
                    "name": item["name"].strip(),
                    "quantity": float(item.get("quantity", 1.0)),
                    "unit_price": float(item.get("unit_price", 0.0)),
                    "total_price": float(item.get("total_price", 0.0)),
                    "tax_category": item.get("tax_category", "A")
                }
                
                # Sprawdź czy ceny się zgadzają
                expected_total = cleaned_item["quantity"] * cleaned_item["unit_price"]
                if abs(cleaned_item["total_price"] - expected_total) > 0.01:
                    cleaned_item["total_price"] = expected_total
                    
                cleaned_items.append(cleaned_item)
                
        logger.info(f"Oczyszczono i deduplikowano produkty: {len(items)} → {len(cleaned_items)}")
        return cleaned_items


class EnhancedReceiptAnalysisAgent(ReceiptAnalysisAgent):
    """Rozszerzona wersja agenta do analizy paragonów"""

    def __init__(self, **kwargs: Any) -> None:
        super().__init__(name="EnhancedReceiptAnalysisAgent", **kwargs)

    async def process(self, input_data: dict[str, Any]) -> AgentResponse:
        """Przetwarza tekst OCR i wyciąga strukturalne dane paragonu"""
        return await super().process(input_data)

    def _fallback_parser(self, ocr_text: str) -> dict:
        """Ulepszony fallback parser z lepszą ekstrakcją produktów"""
        try:
            # Wyczyść tekst
            text = ocr_text.upper()
            
            # Rozpoznaj sklep
            store_name = self._extract_store_name(text)
            
            # Rozpoznaj datę
            date = self._extract_date(text)
            
            # Rozpoznaj produkty z ulepszonym algorytmem
            items = self._extract_items_improved(text)
            
            # Oblicz sumę
            total = sum(item.get('total_price', 0) for item in items)
            
            return {
                "store_name": store_name,
                "date": date,
                "items": items,
                "total_amount": total
            }
            
        except Exception as e:
            logger.error(f"Fallback parser error: {e}")
            return {
                "store_name": "Nieznany sklep",
                "date": "2025-07-21",
                "items": [],
                "total_amount": 0.0
            }

    def _extract_store_name(self, text: str) -> str:
        """Rozpoznaj nazwę sklepu z ulepszonymi wzorcami"""
        store_patterns = {
            r'LIDL.*POLSKA': 'Lidl',
            r'BIEDRONKA': 'Biedronka', 
            r'KAUFLAND': 'Kaufland',
            r'TESCO': 'Tesco',
            r'CARREFOUR': 'Carrefour',
            r'AUCHAN': 'Auchan',
            r'LEWIATAN': 'Lewiatan',
            r'SPAR': 'Spar',
            r'ŻABKA': 'Żabka',
            r'INKA': 'Inka',
            r'GROSZEK': 'Groszek',
            r'POLOMARKET': 'PoloMarket',
            r'NETTO': 'Netto',
            r'ALDI': 'Aldi',
            r'PENNY': 'Penny'
        }
        
        for pattern, store in store_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                return store
                
        return "Nieznany sklep"

    def _validate_and_fix_date(self, date_str: str) -> str:
        """Waliduje i poprawia datę"""
        try:
            # Sprawdź czy data jest już w formacie YYYY-MM-DD
            if re.match(r'^\d{4}-\d{2}-\d{2}$', date_str):
                # Sprawdź czy data jest rozsądna (nie w przyszłości i nie starsza niż 10 lat)
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                today = datetime.now()
                ten_years_ago = today - timedelta(days=3650)
                
                if ten_years_ago <= date_obj <= today:
                    return date_str
                else:
                    return today.strftime('%Y-%m-%d')
            
            # Próbuj różne formaty dat
            date_formats = [
                '%d.%m.%Y',  # DD.MM.YYYY
                '%Y-%m-%d',  # YYYY-MM-DD
                '%d/%m/%Y',  # DD/MM/YYYY
                '%d.%m.%y',  # DD.MM.YY
                '%Y/%m/%d',  # YYYY/MM/DD
            ]
            
            for fmt in date_formats:
                try:
                    date_obj = datetime.strptime(date_str, fmt)
                    today = datetime.now()
                    ten_years_ago = today - timedelta(days=3650)
                    
                    if ten_years_ago <= date_obj <= today:
                        return date_obj.strftime('%Y-%m-%d')
                except ValueError:
                    continue
                    
            # Jeśli nie udało się sparsować, zwróć dzisiejszą datę
            return datetime.now().strftime('%Y-%m-%d')
            
        except Exception as e:
            logger.warning(f"Date validation error: {e}")
            return datetime.now().strftime('%Y-%m-%d')

    def _extract_date(self, text: str) -> str:
        """Rozpoznaj datę z ulepszonymi wzorcami i walidacją"""
        # Wzorce dat
        date_patterns = [
            r'(\d{2})\.(\d{2})\.(\d{4})',  # DD.MM.YYYY
            r'(\d{4})-(\d{2})-(\d{2})',    # YYYY-MM-DD
            r'(\d{2})/(\d{2})/(\d{4})',    # DD/MM/YYYY
            r'DATA.*?(\d{2})\.(\d{2})\.(\d{4})',  # DATA DD.MM.YYYY
            r'(\d{2})\.(\d{2})\.(\d{2})',  # DD.MM.YY
            r'DATA.*?(\d{2})/(\d{2})/(\d{4})',  # DATA DD/MM/YYYY
            r'(\d{4})/(\d{2})/(\d{2})',    # YYYY/MM/DD
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                if len(match.groups()) == 3:
                    day, month, year = match.groups()
                    if len(year) == 2:
                        year = '20' + year
                    
                    # Sprawdź czy miesiąc i dzień są rozsądne
                    try:
                        month_int = int(month)
                        day_int = int(day)
                        year_int = int(year)
                        
                        if 1 <= month_int <= 12 and 1 <= day_int <= 31:
                            date_str = f"{year}-{month:02d}-{day:02d}"
                            return self._validate_and_fix_date(date_str)
                    except ValueError:
                        continue
                    
        return datetime.now().strftime('%Y-%m-%d')

    def _extract_items_improved(self, text: str) -> list:
        """Ulepszona ekstrakcja produktów z lepszymi wzorcami"""
        items = []
        
        # Wzorce produktów z cenami
        product_patterns = [
            # Wzorzec: NAZWA_PRODUKTU CENA PLN
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s]+)\s+(\d+[.,]\d{2})\s*PLN',
            # Wzorzec: NAZWA_PRODUKTU CENA
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s]+)\s+(\d+[.,]\d{2})',
            # Wzorzec: NAZWA_PRODUKTU x CENA
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s]+)\s+x\s+(\d+[.,]\d{2})',
            # Wzorzec: NAZWA_PRODUKTU ILOŚĆ x CENA
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s]+)\s+(\d+)\s*x\s+(\d+[.,]\d{2})',
            # Wzorzec: NAZWA_PRODUKTU CENA A/B/C (kategoria podatkowa)
            r'([A-ZĄĆĘŁŃÓŚŹŻ\s]+)\s+(\d+[.,]\d{2})\s*([ABC])',
        ]
        
        # Słowa do filtrowania (nie są produktami)
        filter_words = {
            'SUMA', 'RAZEM', 'TOTAL', 'PTU', 'PODATEK', 'RABAT', 'ZNIŻKA',
            'KARTA', 'PŁATNOŚĆ', 'GOTÓWKA', 'KARTA PŁATNICZA', 'NIP',
            'DATA', 'GODZINA', 'KASA', 'KASJER', 'NUMER', 'TRANSKCJI',
            'PODSUMOWANIE', 'ZAKUPÓW', 'PUNKTY', 'KLIENTA', 'STANOWISKO',
            'SPRZEDAŻ', 'PODATKOWANA', 'BRUTTO', 'NETTO', 'PODATEK',
            'SUMA PTU', 'SUMA PLN', 'BLANCO', 'KARTAŁAPALNICZAB',
            'REKLAMOWKA', 'MALAREC', 'LIDLPLUSKUPON', 'KUPONY',
            'WYKORZYSTANE', 'KUPONY', 'CALURYURECHAMI', 'NIGDALZIEIIROTOWCENI',
            'ITANC', 'HOENAWYWOCJEWZAYZYDAZE', 'AUOESCAAACICC', 'AODAZACAWEHSLACA',
            'RABOEN', 'ETEELKMMOOEK', 'LOCENABAKENDESKNECAJANATNKSETEELSNSTAOCTCARTEJKTEEELET',
            'KOPMEZNWCATWLA', 'OUEKNUNCZHOERNSZAANIREDNIEADTNETELANSIIDECAZDRET',
            'ASP', 'LEST', 'MIEJSCEZAKUPU', 'AREZENULRYZENRDAEZ', 'JLBZZYNONSCA',
            'GR', 'MZREZZWEI', 'SZCZEGOLYSKLEPU'
        }
        
        for pattern in product_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                groups = match.groups()
                
                if len(groups) >= 2:
                    product_name = groups[0].strip()
                    price_str = groups[1].replace(',', '.')
                    
                    # Sprawdź czy to nie jest słowo do filtrowania
                    if any(filter_word in product_name.upper() for filter_word in filter_words):
                        continue
                        
                    # Sprawdź czy nazwa produktu ma sens (min 3 znaki)
                    if len(product_name) < 3:
                        continue
                        
                    try:
                        price = float(price_str)
                        quantity = 1.0
                        tax_category = "B"  # Domyślna kategoria
                        
                        # Jeśli mamy ilość w matchu
                        if len(groups) >= 3 and groups[2].isdigit():
                            quantity = float(groups[2])
                        elif len(groups) >= 3 and groups[2] in ['A', 'B', 'C']:
                            tax_category = groups[2]
                            
                        # Oblicz total_price
                        total_price = quantity * price
                        
                        # Sprawdź czy cena jest rozsądna (0.01 - 1000 PLN)
                        if 0.01 <= price <= 1000:
                            items.append({
                                "name": product_name,
                                "quantity": quantity,
                                "unit_price": price,
                                "total_price": total_price,
                                "tax_category": tax_category
                            })
                            
                    except ValueError:
                        continue
                        
        return items
