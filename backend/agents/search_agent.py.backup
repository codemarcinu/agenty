from collections.abc import AsyncGenerator
import logging
from typing import Any
import re

from backend.agents.base_agent import BaseAgent
from backend.agents.interfaces import AgentResponse
from backend.agents.response_generator import ResponseGenerator
from backend.agents.tools.search_providers import (
    DuckDuckGoSearchProvider,
    WikipediaSearchProvider,
)
from backend.core.decorators import handle_exceptions
from backend.core.hybrid_llm_client import hybrid_llm_client
from backend.core.search_cache import search_cache
from backend.integrations.web_search import web_search
from backend.core.anti_hallucination_decorator import with_anti_hallucination, AntiHallucinationConfig
from backend.core.anti_hallucination_system import ValidationLevel

logger = logging.getLogger(__name__)


class SearchAgentInput:
    """Input model for SearchAgent"""

    def __init__(
        self, query: str, model: str | None = None, max_results: int = 5
    ) -> None:
        self.query = query
        self.model = (
            model or "SpeakLeash/bielik-11b-v2.3-instruct:Q5_K_M"
        )  # Use Bielik-11B as default
        self.max_results = max_results


class SearchAgent(BaseAgent):
    """
    Agent do wyszukiwania informacji z rÃ³Å¼nych ÅºrÃ³deÅ‚ (Wikipedia, DuckDuckGo).
    WybÃ³r providera na podstawie heurystyki, prefixu lub fallbacku.
    Zintegrowany z ResponseGenerator dla spÃ³jnych odpowiedzi.
    Zoptymalizowany z cache'owaniem wynikÃ³w wyszukiwania.
    """

    def __init__(self, config: dict[str, Any] | None = None, **kwargs) -> None:
        super().__init__(name="SearchAgent", **kwargs)
        self.search_providers = {
            "wikipedia": WikipediaSearchProvider(),
            "duck": DuckDuckGoSearchProvider(),
        }
        self.default_provider = "duck"
        self.response_generator = ResponseGenerator()
        self.cache_enabled = config.get("cache_enabled", True) if config else True

        # Initialize HTTP client for DuckDuckGo search
        import httpx

        self.http_client = httpx.AsyncClient(timeout=30.0)

        # Initialize web_search and knowledge verification threshold
        self.web_search = web_search
        self.knowledge_verification_threshold = (
            config.get("knowledge_verification_threshold", 0.7) if config else 0.7
        )

        # Ignoruj nieznane kwargs przekazywane przez DI, testy, monitoring, kontenery

    def detect_search_type(self, query: str) -> str:
        """
        Wybiera providera na podstawie prefixu lub heurystyki.
        """
        q = query.lower().strip()
        if q.startswith("wikipedia:"):
            return "wikipedia"
        if q.startswith(("duck:", "duckduckgo:")):
            return "duck"
        # Heurystyka encyklopedyczna
        wiki_keywords = [
            "wikipedia",
            "kto to",
            "co to",
            "definicja",
            "biografia",
            "historia",
            "encyklopedia",
        ]
        if any(kw in q for kw in wiki_keywords):
            return "wikipedia"
        # Heurystyka webowa
        duck_keywords = [
            "szukaj",
            "search",
            "find",
            "najlepsze strony",
            "aktualnoÅ›ci",
            "news",
        ]
        if any(kw in q for kw in duck_keywords):
            return "duck"
        return self.default_provider

    def format_search_results(
        self, results: list[dict[str, Any]], provider: str
    ) -> str:
        """
        Formatuje wyniki wyszukiwania w czytelny tekst.
        """
        if not results:
            return "Nie znaleziono wynikÃ³w wyszukiwania."

        formatted_results = []
        for i, result in enumerate(results[:5], 1):  # Maksymalnie 5 wynikÃ³w
            title = result.get("title", "Brak tytuÅ‚u")
            snippet = result.get("snippet", "Brak opisu")

            if provider == "wikipedia":
                pageid = result.get("pageid", "")
                formatted_results.append(
                    f"{i}. **{title}** (ID: {pageid})\n   {snippet}"
                )
            else:  # duck
                url = result.get("url", "")
                formatted_results.append(
                    f"{i}. **{title}**\n   {snippet}\n   URL: {url}"
                )

        return "\n\n".join(formatted_results)

    @with_anti_hallucination(AntiHallucinationConfig(
        validation_level=ValidationLevel.STRICT,
        log_validation=True
    ))
    async def process(self, input_data: dict[str, Any]) -> AgentResponse:
        """
        GÅ‚Ã³wna metoda przetwarzania zgodna z interfejsem BaseAgent.
        """
        query = input_data.get("query", "")
        context = input_data.get("context")

        if not query:
            return AgentResponse(
                success=False,
                error="Brak zapytania wyszukiwania",
                text="ProszÄ™ podaÄ‡ zapytanie do wyszukiwania.",
            )

        try:
            results = await self.process_request(query, context)
            
            # ANTY-HALUCYNACYJNA WALIDACJA WYNIKÃ“W
            validated_results = self._validate_search_results(results, query)
            
            if not validated_results["is_valid"]:
                return AgentResponse(
                    success=True,
                    text=f"Nie znalazÅ‚em zweryfikowanych informacji na temat: '{query}'. {validated_results['reason']}",
                    data={
                        "search_results": [],
                        "provider_used": "none",
                        "anti_hallucination": True,
                        "validation_failed": True,
                        "reason": validated_results["reason"]
                    },
                    metadata={
                        "agent_type": "search",
                        "results_count": 0,
                        "query": query,
                        "cache_used": self.cache_enabled,
                        "anti_hallucination_triggered": True,
                    },
                )
            
            formatted_text = self.format_search_results(
                results, self.detect_search_type(query)
            )

            response = AgentResponse(
                success=True,
                text=formatted_text,
                data={
                    "search_results": results,
                    "provider_used": self.detect_search_type(query),
                    "anti_hallucination": True,
                    "validation_passed": True,
                },
                metadata={
                    "agent_type": "search",
                    "results_count": len(results),
                    "query": query,
                    "cache_used": self.cache_enabled,
                },
            )

            # UÅ¼yj ResponseGenerator do finalnego formatowania
            if context:
                return await self.response_generator.generate_response(
                    context, response
                )
            return response

        except Exception as e:
            logger.error(f"SearchAgent error: {e}")
            error_response = AgentResponse(
                success=False,
                error=f"BÅ‚Ä…d wyszukiwania: {e!s}",
                text=f"Przepraszam, wystÄ…piÅ‚ bÅ‚Ä…d podczas wyszukiwania: {e!s}",
            )

            if context:
                return await self.response_generator.generate_response(
                    context, error_response
                )
            return error_response

    async def process_request(
        self, query: str, context: dict[str, Any] | None = None
    ) -> list[dict[str, Any]]:
        """
        Przetwarza zapytanie, wybiera providera, obsÅ‚uguje fallback i cache.
        Zwraca listÄ™ wynikÃ³w (tytuÅ‚, snippet, url/pageid).
        """
        provider_key = self.detect_search_type(query)

        # SprawdÅº cache jeÅ›li wÅ‚Ä…czony
        if self.cache_enabled:
            cached_results = search_cache.get(query, provider_key)
            if cached_results:
                logger.info(f"Cache hit for query: {query}, provider: {provider_key}")
                return cached_results

        provider = self.search_providers[provider_key]
        try:
            results = await provider.search(query)
            if results:
                # Zapisz w cache jeÅ›li wÅ‚Ä…czony
                if self.cache_enabled:
                    search_cache.set(query, provider_key, results)
                return results

            # Fallback na drugi provider jeÅ›li brak wynikÃ³w
            fallback_key = "duck" if provider_key == "wikipedia" else "wikipedia"
            fallback_provider = self.search_providers[fallback_key]

            # SprawdÅº cache dla fallback providera
            if self.cache_enabled:
                cached_fallback = search_cache.get(query, fallback_key)
                if cached_fallback:
                    logger.info(
                        f"Cache hit for fallback query: {query}, provider: {fallback_key}"
                    )
                    return cached_fallback

            fallback_results = await fallback_provider.search(query)

            # Zapisz fallback wyniki w cache
            if self.cache_enabled and fallback_results:
                search_cache.set(query, fallback_key, fallback_results)

            return fallback_results

        except Exception as e:
            logger.error(f"SearchAgent error with {provider_key}: {e}")
            # Fallback na drugi provider w razie bÅ‚Ä™du
            fallback_key = "duck" if provider_key == "wikipedia" else "wikipedia"
            try:
                fallback_provider = self.search_providers[fallback_key]

                # SprawdÅº cache dla fallback providera
                if self.cache_enabled:
                    cached_fallback = search_cache.get(query, fallback_key)
                    if cached_fallback:
                        return cached_fallback

                fallback_results = await fallback_provider.search(query)

                # Zapisz fallback wyniki w cache
                if self.cache_enabled and fallback_results:
                    search_cache.set(query, fallback_key, fallback_results)

                return fallback_results
            except Exception as e2:
                logger.error(f"SearchAgent fallback error: {e2}")
                return []

    @handle_exceptions(max_retries=2)
    async def process_with_verification(
        self, input_data: dict[str, Any]
    ) -> AgentResponse:
        """Main processing method - performs search and returns results in a stream"""
        query = input_data.get("query", "")
        if not query:
            return AgentResponse(
                success=False,
                error="Query is required",
                text="Przepraszam, ale potrzebujÄ™ zapytania do wyszukania.",
            )

        max_results = input_data.get("max_results", 5)
        use_perplexity = input_data.get("use_perplexity", True)  # DomyÅ›lnie Perplexity
        verify_knowledge = input_data.get(
            "verify_knowledge", True
        )  # DomyÅ›lnie wÅ‚Ä…czona weryfikacja

        async def stream_generator() -> AsyncGenerator[str, None]:
            try:
                yield "Rozpoczynam wyszukiwanie z weryfikacjÄ… wiedzy...\n"

                if use_perplexity:
                    logger.info(f"Using Perplexity for search query: {query}")
                    yield "Korzystam z Perplexity...\n"
                    search_results = await self.web_search.search(
                        query, max_results=max_results
                    )
                    if search_results:
                        # Format results as content
                        content_parts = []
                        for result in search_results:
                            content_parts.append(f"**{result['title']}**")
                            content_parts.append(f"{result['snippet']}")
                            content_parts.append(f"Å¹rÃ³dÅ‚o: {result['url']}\n")
                        yield "\n".join(content_parts)
                    else:
                        yield "Nie znaleziono wynikÃ³w wyszukiwania."
                else:
                    # UÅ¼yj ulepszonego systemu wyszukiwania z weryfikacjÄ… wiedzy
                    logger.info(f"Using enhanced web search for query: {query}")
                    yield "Korzystam z ulepszonego systemu wyszukiwania...\n"

                    if verify_knowledge:
                        yield "ðŸ” WeryfikujÄ™ wiarygodnoÅ›Ä‡ ÅºrÃ³deÅ‚...\n"
                        enhanced_result = await self._enhanced_search_with_verification(
                            query, max_results
                        )
                        yield enhanced_result
                    else:
                        basic_result = await self._basic_search(query, max_results)
                        yield basic_result

            except Exception as e:
                logger.error(f"[SearchAgent] Error during stream generation: {e}")
                yield f"WystÄ…piÅ‚ wewnÄ™trzny bÅ‚Ä…d: {e}"

        return AgentResponse(
            success=True,
            text_stream=stream_generator(),
            message="Search stream started.",
        )

    async def _enhanced_search_with_verification(
        self, query: str, max_results: int
    ) -> str:
        """Perform enhanced search with knowledge verification"""
        try:
            # UÅ¼yj nowego systemu wyszukiwania z weryfikacjÄ…
            search_response = await web_search.search_with_verification(
                query, max_results
            )

            if not search_response["results"]:
                return "Nie znaleziono odpowiednich wynikÃ³w wyszukiwania."

            # Analizuj wyniki wyszukiwania
            verified_results = [
                r for r in search_response["results"] if r["knowledge_verified"]
            ]
            total_results = len(search_response["results"])
            verification_score = search_response["knowledge_verification_score"]

            # Przygotuj odpowiedÅº
            response_parts = []
            response_parts.append(f"ðŸ“Š **Wyniki wyszukiwania dla: '{query}'**\n")
            response_parts.append(f"ðŸ” Znaleziono {total_results} wynikÃ³w")
            response_parts.append(
                f"âœ… Zweryfikowane ÅºrÃ³dÅ‚a: {len(verified_results)}/{total_results}"
            )
            response_parts.append(
                f"ðŸ“ˆ WskaÅºnik wiarygodnoÅ›ci: {verification_score:.2f}\n"
            )

            # Dodaj najlepsze wyniki
            response_parts.append("**Najlepsze wyniki:**\n")
            for i, result in enumerate(search_response["results"][:3], 1):
                verification_icon = "âœ…" if result["knowledge_verified"] else "âš ï¸"
                confidence_icon = (
                    "ðŸŸ¢"
                    if result["confidence"] > 0.7
                    else "ðŸŸ¡" if result["confidence"] > 0.4 else "ðŸ”´"
                )

                response_parts.append(
                    f"{i}. {verification_icon} {confidence_icon} **{result['title']}**"
                )
                response_parts.append(f"   ðŸ“ {result['snippet'][:150]}...")
                response_parts.append(f"   ðŸ”— {result['url']}")
                response_parts.append(f"   ðŸ“Š WiarygodnoÅ›Ä‡: {result['confidence']:.2f}")
                response_parts.append("")

            # Dodaj rekomendacjÄ™ na podstawie weryfikacji
            if verification_score > self.knowledge_verification_threshold:
                response_parts.append(
                    "âœ… **Wysoka wiarygodnoÅ›Ä‡ ÅºrÃ³deÅ‚** - wyniki sÄ… godne zaufania."
                )
            elif verification_score > 0.4:
                response_parts.append(
                    "âš ï¸ **Åšrednia wiarygodnoÅ›Ä‡ ÅºrÃ³deÅ‚** - zalecana dodatkowa weryfikacja."
                )
            else:
                response_parts.append(
                    "ðŸ”´ **Niska wiarygodnoÅ›Ä‡ ÅºrÃ³deÅ‚** - zalecana ostroÅ¼noÅ›Ä‡ przy interpretacji."
                )

            return "\n".join(response_parts)

        except Exception as e:
            logger.error(f"Error in enhanced search: {e}")
            return f"BÅ‚Ä…d podczas wyszukiwania: {e}"

    async def _basic_search(self, query: str, max_results: int) -> str:
        """Perform basic search without verification"""
        try:
            results = await web_search.search(query, max_results)

            if not results:
                return "Nie znaleziono odpowiednich wynikÃ³w wyszukiwania."

            response_parts = []
            response_parts.append(f"ðŸ“Š **Wyniki wyszukiwania dla: '{query}'**\n")

            for i, result in enumerate(results[:3], 1):
                response_parts.append(f"{i}. **{result['title']}**")
                response_parts.append(f"   ðŸ“ {result['snippet'][:150]}...")
                response_parts.append(f"   ðŸ”— {result['url']}")
                response_parts.append("")

            return "\n".join(response_parts)

        except Exception as e:
            logger.error(f"Error in basic search: {e}")
            return f"BÅ‚Ä…d podczas wyszukiwania: {e}"

    async def _perform_search(
        self, query: str, model: str, max_results: int
    ) -> dict[str, Any]:
        """Perform search using Perplexity API"""
        try:
            # Translate query to English for better results
            english_query = await self._translate_to_english(query, model)

            # Perform search with Perplexity
            search_results = await self.web_search.search(
                query=english_query,
                max_results=max_results,
            )

            if search_results:
                # Format results as content
                content_parts = []
                for result in search_results:
                    content_parts.append(f"**{result['title']}**")
                    content_parts.append(f"{result['snippet']}")
                    content_parts.append(f"Å¹rÃ³dÅ‚o: {result['url']}")

                content = "\n\n".join(content_parts)

                # Translate response back to Polish if needed
                polish_response = await self._translate_to_polish(content, model)

                return {
                    "success": True,
                    "content": polish_response,
                    "source": "web_search",
                    "query": query,
                }
            return {"success": False, "error": "No results found", "content": ""}

        except Exception as e:
            logger.error(f"Error in Perplexity search: {e}")
            return {"success": False, "error": str(e), "content": ""}

    async def _duckduckgo_search(self, query: str) -> dict[str, Any]:
        """Fallback search using DuckDuckGo"""
        try:
            # Simple DuckDuckGo search implementation
            search_url = f"https://api.duckduckgo.com/?q={query}&format=json&no_html=1&skip_disambig=1"

            response = await self.http_client.get(search_url)
            response.raise_for_status()

            data = response.json()

            # Extract relevant information
            abstract = data.get("Abstract", "")
            answer = data.get("Answer", "")
            related_topics = data.get("RelatedTopics", [])

            # Combine results
            content_parts = []
            if answer:
                content_parts.append(f"OdpowiedÅº: {answer}")
            if abstract:
                content_parts.append(f"Opis: {abstract}")
            if related_topics:
                topics = [topic.get("Text", "") for topic in related_topics[:3]]
                content_parts.append(f"PowiÄ…zane tematy: {'; '.join(topics)}")

            content = (
                "\n\n".join(content_parts)
                if content_parts
                else "Nie znaleziono odpowiednich wynikÃ³w."
            )

            return {
                "success": True,
                "content": content,
                "source": "duckduckgo",
                "query": query,
            }

        except Exception as e:
            logger.error(f"Error in DuckDuckGo search: {e}")
            return {"success": False, "error": str(e), "content": ""}

    async def _translate_to_english(self, polish_query: str, model: str) -> str:
        """Translate Polish query to English for better search results"""
        prompt = (
            f"PrzetÅ‚umacz poniÅ¼sze zapytanie z jÄ™zyka polskiego na angielski:\n\n"
            f"Zapytanie: '{polish_query}'\n\n"
            f"ZwrÃ³Ä‡ tylko tÅ‚umaczenie, bez dodatkowego tekstu."
        )

        try:
            response = await hybrid_llm_client.chat(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": "JesteÅ› pomocnym asystentem, ktÃ³ry tÅ‚umaczy zapytania z polskiego na angielski.",
                    },
                    {"role": "user", "content": prompt},
                ],
                stream=False,
            )

            if not response or not isinstance(response, dict):
                return polish_query

            content = response.get("message", {}).get("content", "")
            if not content:
                return polish_query

            # Clean up the response
            content = content.strip()
            if content.startswith('"') and content.endswith('"'):
                content = content[1:-1]

            return content if content else polish_query

        except Exception as e:
            logger.error(f"Translation error: {e}")
            return polish_query

    async def _translate_to_polish(self, english_content: str, model: str) -> str:
        """Translate English content back to Polish"""
        prompt = (
            f"PrzetÅ‚umacz poniÅ¼szÄ… treÅ›Ä‡ z jÄ™zyka angielskiego na polski:\n\n"
            f"TreÅ›Ä‡: '{english_content}'\n\n"
            f"ZwrÃ³Ä‡ tylko tÅ‚umaczenie, bez dodatkowego tekstu."
        )

        try:
            response = await hybrid_llm_client.chat(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": "JesteÅ› pomocnym asystentem, ktÃ³ry tÅ‚umaczy treÅ›Ä‡ z angielskiego na polski.",
                    },
                    {"role": "user", "content": prompt},
                ],
                stream=False,
            )

            if not response or not isinstance(response, dict):
                return english_content

            content = response.get("message", {}).get("content", "")
            return content.strip() if content else english_content

        except Exception as e:
            logger.error(f"Translation error: {e}")
            return english_content

    def _validate_search_results(self, results: list[dict[str, Any]], query: str) -> dict[str, Any]:
        """Waliduje wyniki wyszukiwania pod kÄ…tem halucynacji"""
        if not results:
            return {
                "is_valid": False,
                "reason": "Brak wynikÃ³w wyszukiwania"
            }
        
        # SprawdÅº czy wyniki zawierajÄ… niezweryfikowane informacje
        query_lower = query.lower()
        
        # Wzorce halucynacji dla wyszukiwania
        hallucination_patterns = [
            # Wzorce dla osÃ³b bez ÅºrÃ³deÅ‚
            r"byÅ‚\s+wybitnym",
            r"urodziÅ‚\s+siÄ™\s+w\s+\d{4}",
            r"zmarÅ‚\s+w\s+\d{4}",
            r"jego\s+najwaÅ¼niejsze\s+osiÄ…gniÄ™cia",
            # Wzorce dla wydarzeÅ„ bez dat
            r"obchodzony\s+jest\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]+dzieÅ„",
            r"upamiÄ™tnia\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]+wydarzenie",
            r"gÅ‚Ã³wne\s+obchody\s+odbywajÄ…\s+siÄ™",
            # Wzorce dla szczegÃ³Å‚owych informacji bez ÅºrÃ³deÅ‚
            r"\d{4}\s+roku",
            r"w\s+\d{4}\s+roku",
            r"od\s+\d{4}\s+do\s+\d{4}",
        ]
        
        # SprawdÅº kaÅ¼dy wynik
        for result in results:
            snippet = result.get("snippet", "").lower()
            title = result.get("title", "").lower()
            
            # SprawdÅº czy wynik zawiera wzorce halucynacji
            for pattern in hallucination_patterns:
                if re.search(pattern, snippet, re.IGNORECASE) or re.search(pattern, title, re.IGNORECASE):
                    return {
                        "is_valid": False,
                        "reason": "Wyniki zawierajÄ… niezweryfikowane informacje"
                    }
        
        # SprawdÅº czy wyniki sÄ… odpowiednie dla zapytania
        if any(word in query_lower for word in ["kto", "kim", "osoba", "biografia"]):
            # Dla zapytaÅ„ o osoby, sprawdÅº czy sÄ… ÅºrÃ³dÅ‚a
            has_sources = any(
                "wikipedia" in result.get("url", "").lower() or
                "encyklopedia" in result.get("url", "").lower() or
                "biografia" in result.get("url", "").lower()
                for result in results
            )
            
            if not has_sources:
                return {
                    "is_valid": False,
                    "reason": "Brak wiarygodnych ÅºrÃ³deÅ‚ dla informacji o osobie"
                }
        
        return {
            "is_valid": True,
            "reason": "Wyniki zweryfikowane"
        }

    @handle_exceptions(max_retries=1)
    def get_dependencies(self) -> list[type]:
        """Return list of dependencies this agent requires"""
        # Import modules here to avoid circular imports
        import httpx
        from backend.core.hybrid_llm_client import hybrid_llm_client
        from backend.integrations.web_search import web_search
        from backend.core.response_generator import ResponseGenerator
        
        return [
            type(httpx),
            type(hybrid_llm_client),
            type(web_search),
            type(ResponseGenerator),
        ]

    def get_metadata(self) -> dict[str, Any]:
        """Zwraca metadane agenta."""
        return {
            "agent_type": "search",
            "capabilities": [
                "web_search",
                "wikipedia_search",
                "fallback_support",
                "caching",
            ],
            "providers": list(self.search_providers.keys()),
            "version": "1.0.0",
            "cache_enabled": self.cache_enabled,
            "cache_stats": search_cache.get_stats() if self.cache_enabled else None,
        }

    def is_healthy(self) -> bool:
        """Check if the agent is healthy and ready to process requests"""
        return True  # Simple health check - could be enhanced

    async def verify_knowledge_claim(
        self, claim: str, context: str = ""
    ) -> dict[str, Any]:
        """Verify a specific knowledge claim against external sources"""
        try:
            # Search for the claim
            search_query = f"{claim} {context}".strip()
            search_response = await web_search.search_with_verification(
                search_query, max_results=3
            )

            # Analyze results for claim verification
            verified_sources = [
                r for r in search_response["results"] if r["knowledge_verified"]
            ]
            high_confidence_sources = [
                r for r in search_response["results"] if r["confidence"] > 0.7
            ]

            verification_result = {
                "claim": claim,
                "verified": len(verified_sources) > 0,
                "confidence_score": search_response["knowledge_verification_score"],
                "high_confidence_sources": len(high_confidence_sources),
                "total_sources": len(search_response["results"]),
                "supporting_evidence": [r["snippet"] for r in verified_sources[:2]],
                "sources": [r["url"] for r in verified_sources[:2]],
            }

            return verification_result

        except Exception as e:
            logger.error(f"Error verifying knowledge claim: {e}")
            return {
                "claim": claim,
                "verified": False,
                "error": str(e),
                "confidence_score": 0.0,
            }
