#!/usr/bin/env python3
"""
Test skrypt do sprawdzenia optymalizacji modelu Bielik w general_conversation_agent
"""

import asyncio
import logging
from pathlib import Path
import sys
import os

# Dodaj gÅ‚Ã³wny katalog do PYTHONPATH
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "src"))

# Mock dla testowania bez peÅ‚nych zaleÅ¼noÅ›ci
class MockModelComplexity:
    SIMPLE = "simple"
    STANDARD = "standard"  
    COMPLEX = "complex"

# Skonfiguruj logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_bielik_optimization():
    """Test optymalizacji modelu Bielik"""
    
    print("ðŸ”¬ TESTOWANIE OPTYMALIZACJI MODELU BIELIK")
    print("="*50)
    
    # UtwÃ³rz instancjÄ™ agenta
    agent = GeneralConversationAgent()
    
    # Test cases z rÃ³Å¼nÄ… zÅ‚oÅ¼onoÅ›ciÄ…
    test_cases = [
        {
            "query": "CzeÅ›Ä‡!",
            "expected_complexity": ModelComplexity.SIMPLE,
            "expected_model": "SpeakLeash/bielik-4.5b-v3.0-instruct:Q8_0",
            "description": "Proste pozdrowienie"
        },
        {
            "query": "Co to jest sztuczna inteligencja?",
            "expected_complexity": ModelComplexity.STANDARD,
            "expected_model": "SpeakLeash/bielik-7b-v2.1-instruct:Q5_K_M",
            "description": "Standardowe pytanie o definicjÄ™"
        },
        {
            "query": "Przeanalizuj rÃ³Å¼nice miÄ™dzy rÃ³Å¼nymi podejÅ›ciami do uczenia maszynowego, przedstaw argumenty za i przeciw kaÅ¼demu z nich, oraz zaproponuj strategiÄ™ implementacji w polskiej firmie technologicznej.",
            "expected_complexity": ModelComplexity.COMPLEX,
            "expected_model": "SpeakLeash/bielik-11b-v2.3-instruct:Q5_K_M",
            "description": "ZÅ‚oÅ¼one pytanie analityczne"
        }
    ]
    
    print("\nðŸ“Š TESTOWANIE WYBORU MODELU:")
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. {test_case['description']}")
        print(f"   Query: {test_case['query'][:50]}...")
        
        # Test okreÅ›lania zÅ‚oÅ¼onoÅ›ci
        complexity = agent._determine_query_complexity_enhanced(
            test_case['query'], "", ""
        )
        print(f"   âœ… Complexity: {complexity} (expected: {test_case['expected_complexity']})")
        
        # Test wyboru modelu
        model = agent._select_model(complexity, True)
        print(f"   âœ… Model: {model}")
        print(f"   âœ… Expected: {test_case['expected_model']}")
        
        # Test parametrÃ³w Bielik
        params = agent._get_bielik_parameters(complexity, model)
        print(f"   âœ… Parameters: temp={params['temperature']}, max_tokens={params['max_tokens']}")
        
        # Test wykrywania intencji
        intent = agent._detect_user_intent_bielik(test_case['query'])
        print(f"   âœ… Intent: {intent}")
        
        # Test stylu odpowiedzi
        style = agent._get_bielik_response_style(intent, complexity)
        print(f"   âœ… Style: {style['approach'][:40]}...")
    
    print("\nðŸŽ¨ TESTOWANIE TRYBÃ“W KONWERSACYJNYCH:")
    modes = agent._get_bielik_conversation_modes()
    for mode_name, mode_config in modes.items():
        print(f"   â€¢ {mode_name}: {mode_config['description']}")
        print(f"     Temperature: {mode_config['temperature']}")
    
    print("\nðŸ§  TESTOWANIE BUDOWANIA PROMPTÃ“W:")
    test_prompt = agent._build_bielik_optimized_prompt(
        ModelComplexity.STANDARD, "Test context", "Test internet"
    )
    print(f"   âœ… Generated prompt length: {len(test_prompt)} characters")
    print(f"   âœ… Contains 'Bielik': {'Bielik' in test_prompt}")
    print(f"   âœ… Contains Polish context: {'POLSKI KONTEKST' in test_prompt}")
    
    print("\nâœ¨ OPTYMALIZACJA ZAKOÅƒCZONA POMYÅšLNIE!")
    print("\nðŸ“ˆ KORZYÅšCI Z OPTYMALIZACJI:")
    print("   â€¢ Adaptacyjny wybÃ³r modelu Bielik (4.5B â†’ 7B â†’ 11B)")
    print("   â€¢ Zoptymalizowane parametry dla kaÅ¼dego wariantu")
    print("   â€¢ Inteligentne wykrywanie intencji uÅ¼ytkownika")
    print("   â€¢ 6 rÃ³Å¼nych trybÃ³w konwersacyjnych")
    print("   â€¢ Polskie prompty dostosowane do kontekstu kulturowego")
    print("   â€¢ Lepsze wykorzystanie mocy obliczeniowej")

if __name__ == "__main__":
    asyncio.run(test_bielik_optimization())